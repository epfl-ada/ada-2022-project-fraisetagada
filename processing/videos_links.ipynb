{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing: links in video descriptions\n",
    "\n",
    "This notebook processes links in video descriptions. Our goal is to extract URLs that may be related to sponsors, hence giving us a way to identify sponsorships in videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import re\n",
    "from pyspark.sql.functions import col, udf, explode, when\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, DoubleType, LongType, StringType, DateType, ArrayType, BooleanType\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark as ps\n",
    "config = ps.SparkConf()\n",
    "config.set('spark.executor.heartbeatInterval', '3600s')\n",
    "config.set('spark.network.timeout', '7200s')\n",
    "config.set('spark.driver.memory', '16g')\n",
    "sc = ps.SparkContext('local[*]', '', conf=config) # write 'local' for single-threaded execution and 'local[*]' for multi-threaded execution\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_SUBDATASETS = False\n",
    "PATH_METADATAS_SRC = '../data/subdata/yt_metadata_en_sub' if USE_SUBDATASETS else '../data/yt_metadata_en.jsonl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract links from video descriptions\n",
    "\n",
    "Firstly, we extract links using regular expressions. We perform a first filtering to remove urls from sites that are generally not related to sponsors such as Youtube, Twitter, Facebook, Wikipedia, Discord, etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_METADATAS_URLS_DST = '../data/generated/yt_metadata_en_urls.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the invalid URLs\n",
    "PATH_INVALID_URLS = '../data/invalid_urls.csv'\n",
    "\n",
    "invalid_urls_reg = []\n",
    "with open(PATH_INVALID_URLS, 'r') as f:\n",
    "    for line in f:\n",
    "        invalid_urls_reg.append(fr\"(?i)({line.strip()})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_urls(description):\n",
    "    if description is None:\n",
    "        return []\n",
    "        \n",
    "    url_regex = r\"https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)\"\n",
    "    urls = []\n",
    "    for line in description.split(\"\\n\"):\n",
    "        if re.search(url_regex, line):\n",
    "            urlss = [x.group() for x in re.finditer(url_regex, line)] # Find all urls in the line\n",
    "            urlss = [x for x in urlss if not any([re.search(reg, x) for reg in invalid_urls_reg])] # Filter out invalid urls\n",
    "            urls.extend(urlss)\n",
    "    urls = list(set(urls)) # Remove duplicates\n",
    "    return urls\n",
    "\n",
    "# Test the function on basic examples\n",
    "assert(get_urls('There is no link.') == [])\n",
    "assert(get_urls('This is not a valid link: www.special.com/') == [])\n",
    "assert(get_urls('This is a link: https://www.special.com/ and this is another link: https://www.youtube.com/watch?v=2') == ['https://www.special.com/'])\n",
    "assert(get_urls('This is a link: https://www.special.com/ \\n and this is an invalid link: www.special.com/') == ['https://www.special.com/'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPARTITION_SIZE = 500\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"categories\",    StringType(),  True),\n",
    "    StructField(\"channel_id\",    StringType(),  True),\n",
    "    StructField(\"crawl_date\",    DateType(),    True),\n",
    "    StructField(\"description\",   StringType(),  True),\n",
    "    StructField(\"dislike_count\", DoubleType(),  True), # This field must be specified as a double as it is represented as a floating point number\n",
    "    StructField(\"display_id\",    StringType(),  True),\n",
    "    StructField(\"duration\",      IntegerType(), True),\n",
    "    StructField(\"like_count\",    DoubleType(),  True), # This field must be specified as a double as it is represented as a floating point number\n",
    "    StructField(\"tags\",          StringType(),  True),\n",
    "    StructField(\"title\",         StringType(),  True),\n",
    "    StructField(\"upload_date\",   DateType(),    True),\n",
    "    StructField(\"view_count\",    DoubleType(),  True)  # This field must be specified as a double as it is represented as a floating point number\n",
    "])\n",
    "    \n",
    "metadatas = spark.read.json(PATH_METADATAS_SRC, schema=schema) \\\n",
    "    .repartition(REPARTITION_SIZE) \\\n",
    "\n",
    "# Cast the dislike_count, like_count and view_count to their respective integer type\n",
    "metadatas = metadatas \\\n",
    "    .withColumn(\"dislike_count\", metadatas.dislike_count.cast(IntegerType())) \\\n",
    "    .withColumn(\"like_count\", metadatas.like_count.cast(IntegerType())) \\\n",
    "    .withColumn(\"view_count\", metadatas.view_count.cast(LongType()))\n",
    "\n",
    "# Get urls and count of urls in the description\n",
    "get_urls_udf = udf(lambda x: get_urls(x), ArrayType(StringType()))\n",
    "metadatas = metadatas.withColumn('urls', get_urls_udf(col('description')))\n",
    "len_udf = udf(lambda x: len(x), IntegerType())\n",
    "metadatas = metadatas.withColumn('urls_count', len_udf(col('urls')))\n",
    "has_urls_udf = udf(lambda x: x > 0, BooleanType())\n",
    "metadatas = metadatas.withColumn('has_urls', has_urls_udf(col('urls_count')))\n",
    "\n",
    "# Drop the description and take only the videos with at least one url\n",
    "metadatas_urls = metadatas.drop('description')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The links are stored in the `urls` column as a list. The `urls_count` column contains the number of links retrieved in the description. The `has_urls` column is a boolean indicating whether the video has at least one link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+----------+\n",
      "| display_id|                urls|urls_count|\n",
      "+-----------+--------------------+----------+\n",
      "|VPqJmODeZyk|[https://goo.gl/J...|         1|\n",
      "|xLYGF-aCEHk|[https://goo.gl/J...|         1|\n",
      "|TqzfdwSZdRc|[https://goo.gl/J...|         1|\n",
      "|C-dn3p-ZTrM|[https://goo.gl/J...|         1|\n",
      "|OP_njme3T84|[https://goo.gl/J...|         1|\n",
      "+-----------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metadatas_urls.filter(metadatas_urls.has_urls).select('display_id', 'urls', 'urls_count').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+----------+\n",
      "| display_id|urls|urls_count|\n",
      "+-----------+----+----------+\n",
      "|SBqSc91Hn9g|  []|         0|\n",
      "|UuugEl86ESY|  []|         0|\n",
      "|oB4c-yvnbjs|  []|         0|\n",
      "|ZaV-gTCMV8E|  []|         0|\n",
      "|cGvL7AvMfM0|  []|         0|\n",
      "+-----------+----+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metadatas_urls.filter(~metadatas_urls.has_urls).select('display_id', 'urls', 'urls_count').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the two cells below if you want to write the current state of the dataframe to a parquet file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the output folder if it already exists\n",
    "#!rm -f $PATH_METADATAS_URLS_DST # Linux\n",
    "!PowerShell.exe -Command \"Remove-Item -Path $PATH_METADATAS_URLS_DST -Recurse -Force\" # Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadatas_urls.write.parquet(PATH_METADATAS_URLS_DST, partitionBy=['has_urls'], mode='overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse shortened URLs\n",
    "\n",
    "Links are often shortened using services such as Bitly, Google URL Shortener, etc... Unfortunately, they prevent us from knowing the actual destination of the link. We can however process them using scraping and other techniques to extract the actual destination.\n",
    "\n",
    "But first, let us see what are the most common services used to shorten links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "regs = {\n",
    "    'bitly'     : r'https?:\\/\\/bit\\.ly\\/[a-zA-Z0-9\\-\\_]+',\n",
    "    'google'    : r'https?:\\/\\/goo\\.gl\\/[a-zA-Z0-9\\-\\_]+',\n",
    "    'tinyurl'   : r'https?:\\/\\/tinyurl\\.com\\/[a-zA-Z0-9\\-\\_]+',\n",
    "    'adfly'     : r'https?:\\/\\/adf\\.ly\\/[a-zA-Z0-9\\-\\_]+',\n",
    "    'owly'      : r'https?:\\/\\/ow\\.ly\\/[a-zA-Z0-9\\-\\_]+',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for short_name, short_reg in regs.items():\n",
    "    reg_udf = udf(lambda x: len([y for y in x if re.search(short_reg, y)]), IntegerType())\n",
    "    metadatas_urls = metadatas_urls.withColumn(short_name + '_count', reg_udf(col('urls')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+-----------+------------+-------------+-----------+\n",
      "| display_id|                urls|bitly_count|google_count|tinyurl_count|adfly_count|\n",
      "+-----------+--------------------+-----------+------------+-------------+-----------+\n",
      "|7Mnm03pQK0Q|[http://bit.ly/1u...|          1|           0|            0|          0|\n",
      "|uxgD5DIoskE|[http://bit.ly/GR...|          1|           0|            0|          0|\n",
      "|p-onzm-4osU|[https://plus.goo...|          1|           0|            0|          0|\n",
      "|jxdHcBlsxpo|[https://www.folk...|          0|           3|            0|          0|\n",
      "|ptychXTOg4M|[https://www.budo...|          0|           0|            0|          0|\n",
      "+-----------+--------------------+-----------+------------+-------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metadatas_urls \\\n",
    "    .filter(metadatas_urls.urls_count > 0) \\\n",
    "    .select('display_id', 'urls', 'bitly_count', 'google_count', 'tinyurl_count', 'adfly_count') \\\n",
    "    .show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 52,226,513 short urls in the dataset.\n",
      "\n",
      "bitly represents 54.76% of the short urls.\n",
      "google represents 42.13% of the short urls.\n",
      "tinyurl represents 2.58% of the short urls.\n",
      "adfly represents 0.17% of the short urls.\n",
      "owly represents 0.35% of the short urls.\n"
     ]
    }
   ],
   "source": [
    "# Get sum of short urls per shortener\n",
    "short_urls_cnt = metadatas_urls.select('bitly_count', 'google_count', 'tinyurl_count', 'adfly_count', 'owly_count') \\\n",
    "    .agg({'bitly_count': 'sum', 'google_count': 'sum', 'tinyurl_count': 'sum', 'adfly_count': 'sum', 'owly_count': 'sum'}) \\\n",
    "    .collect()[0] \\\n",
    "    .asDict()\n",
    "\n",
    "# Get ratios of short urls per shortener\n",
    "short_urls_total = sum(short_urls_cnt.values())\n",
    "print(f'There are {short_urls_total:,} short urls in the dataset.\\n')\n",
    "for short_name, short_reg in regs.items():\n",
    "    short_urls_ratio = short_urls_cnt[f'sum({short_name}_count)'] / short_urls_total\n",
    "    print(f'{short_name} represents {short_urls_ratio:.2%} of the short urls.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that these results do not assume that links are distinct. Bitly is the most common service used to shorten links, followed by Google URL Shortener. In the next sections, we will see how to extract the actual destination of links shortened by these two services."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resolve Bitly URLs\n",
    "\n",
    "To further enrich our dataset, we write in a separate file all the Bitly URLs found in the dataset. We will then use various tools such as the Bitly API, or simple HTTP requests to resolve the URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_BITLY_URLS = '../data/generated/bitly_urls.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the output folder if it already exists\n",
    "#!rm -f $PATH_BITLY_URLS # Linux\n",
    "!PowerShell.exe -Command \"Remove-Item -Path $PATH_BITLY_URLS -Recurse -Force\" # Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a dataframe with only the bitly urls\n",
    "udf_retrieve_bitly_urls = udf(lambda x: [y for y in x if re.search(regs['bitly'], y)], ArrayType(StringType()))\n",
    "bitly_urls = metadatas_urls \\\n",
    "    .filter(metadatas_urls.bitly_count > 0) \\\n",
    "    .select('urls') \\\n",
    "    .withColumn('url', explode(udf_retrieve_bitly_urls(col('urls')))) \\\n",
    "    .select('url') \\\n",
    "    .distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitly_urls.write.csv(PATH_BITLY_URLS, sep='\\t', header=False, mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2597126"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.read.csv(PATH_BITLY_URLS, sep='\\t', header=False).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a total of $2'597'126$ distinct Bitly URLs in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now assume that the **Bitly URLs have been resolved** in a new tsv file named `bitly_resolved_urls` and we can replace them by their corresponding URLs. The notebook [resolve_bitly_links.ipynb](resolve_bitly_links.ipynb) contains the code to resolve Bitly URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_BITLY_RESOLVED_URLS = '../data/generated/bitly_resolved_urls.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"url\",          StringType(), True),\n",
    "    StructField(\"resolved_url\", StringType(), True),\n",
    "])\n",
    "resolved_urls = spark.read.csv(PATH_BITLY_RESOLVED_URLS, sep='\\t', header=False, schema=schema)\n",
    "\n",
    "resolved_urls.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadatas_resolved_urls = metadatas_urls.withColumn('url', explode('urls')).join(resolved_urls, 'url', 'left')\n",
    "\n",
    "# Show an example\n",
    "metadatas_resolved_urls.filter(metadatas_resolved_urls.display_id == 'FJMKM_TYLy8').select('display_id', 'url', 'resolved_url').show(5, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadatas_resolved_urls = metadatas_resolved_urls \\\n",
    "    .withColumn('url', \\\n",
    "        when(metadatas_resolved_urls.resolved_url.isNotNull(), \n",
    "            metadatas_resolved_urls.resolved_url)\n",
    "        .otherwise(\n",
    "            metadatas_resolved_urls.url)) \\\n",
    "    .drop('resolved_url')\n",
    "metadatas_resolved_urls.filter(metadatas_resolved_urls.display_id == 'FJMKM_TYLy8').select('display_id', 'url').show(5, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resolve Google shortened URLs\n",
    "\n",
    "We also write in a separate file all the Google shortened URLs found in the dataset, and retrieve their actual destination using the [unshorten.me](https://unshorten.me) website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_GOOGL_URLS = '../data/generated/googl_urls.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the output folder if it already exists\n",
    "#!rm -f $PATH_GOOGL_URLS # Linux\n",
    "!PowerShell.exe -Command \"Remove-Item -Path $PATH_GOOGL_URLS -Recurse -Force\" # Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a dataframe with only the bitly urls\n",
    "udf_retrieve_bitly_urls = udf(lambda x: [y for y in x if re.search(regs['google'], y)], ArrayType(StringType()))\n",
    "googl_urls = metadatas_urls \\\n",
    "    .filter(metadatas_urls.google_count > 0) \\\n",
    "    .select('urls') \\\n",
    "    .withColumn('url', explode(udf_retrieve_bitly_urls(col('urls')))) \\\n",
    "    .select('url') \\\n",
    "    .distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "googl_urls.write.csv(PATH_GOOGL_URLS, sep='\\t', header=False, mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1397373"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.read.csv(PATH_GOOGL_URLS, sep='\\t', header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a total of $1'397'373$ distinct Google URLs in the dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('spark')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "58222ebbc97bc15a7dd406d2f7b4dd2466104a906450c8e9dcb294b8e2a99cab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
