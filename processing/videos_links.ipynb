{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing: links in video descriptions\n",
    "\n",
    "This notebook processes links in video descriptions. Our goal is to extract URLs that may be related to sponsors, hence giving us a way to identify sponsorships in videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pyspark.sql.functions import col, udf, explode, when\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, DoubleType, LongType, StringType, DateType, ArrayType, BooleanType\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark as ps\n",
    "config = ps.SparkConf().setAll([\n",
    "    ('spark.network.timeout', '3601s'),\n",
    "    ('spark.executor.heartbeatInterval', '3600s'),\n",
    "])\n",
    "sc = ps.SparkContext('local', '', conf=config)\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_SUBDATASETS = True\n",
    "PATH_METADATAS_SRC = '../data/subdata/yt_metadata_en_sub' if USE_SUBDATASETS else '../data/yt_metadata_en.jsonl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract links from video descriptions\n",
    "\n",
    "Firstly, we extract links using regular expressions. We perform a first filtering to remove urls from sites that are generally not related to sponsors such as Youtube, Twitter, Facebook, Wikipedia, Discord, etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_METADATAS_URLS_DST = '../data/generated/yt_metadata_en_urls.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the invalid URLs\n",
    "PATH_INVALID_URLS = '../data/invalid_urls.csv'\n",
    "\n",
    "invalid_urls_reg = []\n",
    "with open(PATH_INVALID_URLS, 'r') as f:\n",
    "    for line in f:\n",
    "        invalid_urls_reg.append(fr\"(?i)({line.strip()})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_urls(description):\n",
    "    if description is None:\n",
    "        return []\n",
    "        \n",
    "    url_regex = r\"https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)\"\n",
    "    urls = []\n",
    "    for line in description.split(\"\\n\"):\n",
    "        if re.search(url_regex, line):\n",
    "            urlss = [x.group() for x in re.finditer(url_regex, line)] # Find all urls in the line\n",
    "            urlss = [x for x in urlss if not any([re.search(reg, x) for reg in invalid_urls_reg])] # Filter out invalid urls\n",
    "            urls.extend(urlss)\n",
    "    urls = list(set(urls)) # Remove duplicates\n",
    "    return urls\n",
    "\n",
    "# Test the function on basic examples\n",
    "assert(get_urls('There is no link.') == [])\n",
    "assert(get_urls('This is not a valid link: www.special.com/') == [])\n",
    "assert(get_urls('This is a link: https://www.special.com/ and this is another link: https://www.youtube.com/watch?v=2') == ['https://www.special.com/'])\n",
    "assert(get_urls('This is a link: https://www.special.com/ \\n and this is an invalid link: www.special.com/') == ['https://www.special.com/'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"categories\",    StringType(),  True),\n",
    "    StructField(\"channel_id\",    StringType(),  True),\n",
    "    StructField(\"crawl_date\",    DateType(),    True),\n",
    "    StructField(\"description\",   StringType(),  True),\n",
    "    StructField(\"dislike_count\", DoubleType(),  True), # This field must be specified as a double as it is represented as a floating point number\n",
    "    StructField(\"display_id\",    StringType(),  True),\n",
    "    StructField(\"duration\",      IntegerType(), True),\n",
    "    StructField(\"like_count\",    DoubleType(),  True), # This field must be specified as a double as it is represented as a floating point number\n",
    "    StructField(\"tags\",          StringType(),  True),\n",
    "    StructField(\"title\",         StringType(),  True),\n",
    "    StructField(\"upload_date\",   DateType(),    True),\n",
    "    StructField(\"view_count\",    DoubleType(),  True)  # This field must be specified as a double as it is represented as a floating point number\n",
    "])\n",
    "    \n",
    "metadatas = spark.read.json(PATH_METADATAS_SRC, schema=schema)\n",
    "\n",
    "# Cast the dislike_count, like_count and view_count to their respective integer type\n",
    "metadatas = metadatas \\\n",
    "    .withColumn(\"dislike_count\", metadatas.dislike_count.cast(IntegerType())) \\\n",
    "    .withColumn(\"like_count\", metadatas.like_count.cast(IntegerType())) \\\n",
    "    .withColumn(\"view_count\", metadatas.view_count.cast(LongType()))\n",
    "\n",
    "# Get urls and count of urls in the description\n",
    "get_urls_udf = udf(lambda x: get_urls(x), ArrayType(StringType()))\n",
    "metadatas = metadatas.withColumn('urls', get_urls_udf(col('description')))\n",
    "len_udf = udf(lambda x: len(x), IntegerType())\n",
    "metadatas = metadatas.withColumn('urls_count', len_udf(col('urls')))\n",
    "has_urls_udf = udf(lambda x: x > 0, BooleanType())\n",
    "metadatas = metadatas.withColumn('has_urls', has_urls_udf(col('urls_count')))\n",
    "\n",
    "# Drop the description and take only the videos with at least one url\n",
    "metadatas_urls = metadatas.drop('description')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+----------+\n",
      "| display_id|                urls|urls_count|\n",
      "+-----------+--------------------+----------+\n",
      "|PCWIxrl-bcI|[https://mnot.es/...|         7|\n",
      "|P-hm8-F4jGw|[https://www.news...|         5|\n",
      "|CYUBJanMRH4|[http://bit.ly/1u...|         2|\n",
      "|mcjGa3d8SGk|[http://bit.ly/1u...|         2|\n",
      "|QQyWK46rYII|[http://bit.ly/1u...|         2|\n",
      "+-----------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metadatas_urls.filter(metadatas_urls.has_urls).select('display_id', 'urls', 'urls_count').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+----------+\n",
      "| display_id|urls|urls_count|\n",
      "+-----------+----+----------+\n",
      "|7tzde2SR_d0|  []|         0|\n",
      "|s_fdECSDhIk|  []|         0|\n",
      "|XrGSvp3qz7E|  []|         0|\n",
      "|MBls3geaNeo|  []|         0|\n",
      "|-mlMYQ4FDzs|  []|         0|\n",
      "+-----------+----+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metadatas_urls.filter(~metadatas_urls.has_urls).select('display_id', 'urls', 'urls_count').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the two cells below if you want to write the current state of the dataframe to a parquet file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the output folder if it already exists\n",
    "#!rm -f $PATH_METADATAS_URLS_DST # Linux\n",
    "!PowerShell.exe -Command \"Remove-Item -Path $PATH_METADATAS_URLS_DST -Recurse -Force\" # Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadatas_urls.write.parquet(PATH_METADATAS_URLS_DST, partitionBy=['has_urls'], mode='overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resolve Bitly URLs\n",
    "\n",
    "To further enrich our dataset, we write in a separate file all the Bitly URLs found in the dataset. We will then use various tools such as the Bitly API, or simple HTTP requests to resolve the URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_BITLY_URLS = '../data/generated/bitly_urls.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the output folder if it already exists\n",
    "#!rm -f $PATH_BITLY_URLS # Linux\n",
    "!PowerShell.exe -Command \"Remove-Item -Path $PATH_BITLY_URLS -Recurse -Force\" # Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitly_urls = metadatas_urls.select('display_id', explode('urls').alias('url'))\n",
    "bitly_urls = bitly_urls.filter(bitly_urls.url.like('%bit.ly%')).select('url').distinct()\n",
    "\n",
    "bitly_urls.write.csv(PATH_BITLY_URLS, sep='\\t', header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now assume that the **Bitly URLs have been resolved** and we can replace them by their corresponding URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_BITLY_RESOLVED_URLS = '../data/generated/bitly_resolved_urls.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                 url|        resolved_url|\n",
      "+--------------------+--------------------+\n",
      "|http://bit.ly/2Cz...|http://www.musicn...|\n",
      "|http://bit.ly/2Cz...|                None|\n",
      "|https://bit.ly/2w...|https://www.audio...|\n",
      "|http://bit.ly/2Lq...|https://www.audio...|\n",
      "|http://bit.ly/2rw...|https://www.audio...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"url\",          StringType(), True),\n",
    "    StructField(\"resolved_url\", StringType(), True),\n",
    "])\n",
    "resolved_urls = spark.read.csv(PATH_BITLY_RESOLVED_URLS, sep='\\t', header=False, schema=schema)\n",
    "resolved_urls.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+--------------------+\n",
      "| display_id|                 url|        resolved_url|\n",
      "+-----------+--------------------+--------------------+\n",
      "|FJMKM_TYLy8|http://NCS.lnk.to...|                null|\n",
      "|FJMKM_TYLy8|http://bit.ly/ALL...|https://www.youtu...|\n",
      "|FJMKM_TYLy8|http://bit.ly/Dre...|https://soundclou...|\n",
      "|FJMKM_TYLy8|http://bit.ly/NCS...|http://www.youtub...|\n",
      "|FJMKM_TYLy8|http://bit.ly/NCS...|http://www.youtub...|\n",
      "+-----------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metadatas_resolved_urls = metadatas_urls.withColumn('url', explode('urls')).join(resolved_urls, 'url', 'left')\n",
    "metadatas_resolved_urls.filter(metadatas_resolved_urls.display_id == 'FJMKM_TYLy8').select('display_id', 'url', 'resolved_url').show(5, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+\n",
      "| display_id|                 url|\n",
      "+-----------+--------------------+\n",
      "|FJMKM_TYLy8|http://NCS.lnk.to...|\n",
      "|FJMKM_TYLy8|https://www.youtu...|\n",
      "|FJMKM_TYLy8|https://soundclou...|\n",
      "|FJMKM_TYLy8|http://www.youtub...|\n",
      "|FJMKM_TYLy8|http://www.youtub...|\n",
      "+-----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metadatas_resolved_urls = metadatas_resolved_urls \\\n",
    "    .withColumn('url', \\\n",
    "        when(metadatas_resolved_urls.resolved_url.isNotNull(), \n",
    "            metadatas_resolved_urls.resolved_url)\n",
    "        .otherwise(\n",
    "            metadatas_resolved_urls.url)) \\\n",
    "    .drop('resolved_url')\n",
    "metadatas_resolved_urls.filter(metadatas_resolved_urls.display_id == 'FJMKM_TYLy8').select('display_id', 'url').show(5, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('ada')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "93474a10e1612df951114730cd5f83d078f687a48e5e0a7160d033353df33aec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
