{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process links in video descriptions\n",
    "\n",
    "This notebook processes links in video descriptions. Our goal is to extract URLs that may be related to sponsors, hence giving us a way to identify sponsorships in videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pyspark.sql.functions import col, udf, explode\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, DoubleType, LongType, StringType, DateType, ArrayType, BooleanType\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark as ps\n",
    "config = ps.SparkConf().setAll([\n",
    "    ('spark.network.timeout', '3601s'),\n",
    "    ('spark.executor.heartbeatInterval', '3600s'),\n",
    "])\n",
    "sc = ps.SparkContext('local', '', conf=config)\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_SUBDATASETS = False\n",
    "\n",
    "PATH_METADATAS_SRC = '../data/subdata/yt_metadata_en_sub' if USE_SUBDATASETS else '../data/yt_metadata_en.jsonl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract links from video descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we extract links using regular expressions. We perform a first filtering to remove urls from sites that are generally not related to sponsors such as Youtube, Twitter, Facebook, Wikipedia, Discord, etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_METADATAS_URLS_DST = '../data/generated/yt_metadata_en_urls.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the invalid URLs\n",
    "PATH_INVALID_URLS = '../data/invalid_urls.csv'\n",
    "\n",
    "invalid_urls_reg = []\n",
    "with open(PATH_INVALID_URLS, 'r') as f:\n",
    "    for line in f:\n",
    "        invalid_urls_reg.append(fr\"(?i)({line.strip()})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_urls(description):\n",
    "    if description is None:\n",
    "        return []\n",
    "        \n",
    "    url_regex = r\"https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)\"\n",
    "    urls = []\n",
    "    for line in description.split(\"\\n\"):\n",
    "        if re.search(url_regex, line):\n",
    "            urlss = [x.group() for x in re.finditer(url_regex, line)] # Find all urls in the line\n",
    "            urlss = [x for x in urlss if not any([re.search(reg, x) for reg in invalid_urls_reg])] # Filter out invalid urls\n",
    "            urls.extend(urlss)\n",
    "    urls = list(set(urls)) # Remove duplicates\n",
    "    return urls\n",
    "\n",
    "# Test the function on basic examples\n",
    "assert(get_urls('There is no link.') == [])\n",
    "assert(get_urls('This is not a valid link: www.special.com/') == [])\n",
    "assert(get_urls('This is a link: https://www.special.com/ and this is another link: https://www.youtube.com/watch?v=2') == ['https://www.special.com/'])\n",
    "assert(get_urls('This is a link: https://www.special.com/ \\n and this is an invalid link: www.special.com/') == ['https://www.special.com/'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Remove-Item : Impossible de trouver le chemin d'acc�s �\n",
      "C:\\Users\\admin\\Documents\\ADA\\Project\\data\\generated\\yt_metadata_en_urls.parquet\n",
      "�, car il n'existe pas.\n",
      "Au caract�re Ligne:1 : 1\n",
      "+ Remove-Item -Path ../data/generated/yt_metadata_en_urls.parquet -Recu ...\n",
      "+ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "    + CategoryInfo          : ObjectNotFound: (C:\\Users\\admin\\...en_urls.parqu \n",
      "   et:String) [Remove-Item], ItemNotFoundException\n",
      "    + FullyQualifiedErrorId : PathNotFound,Microsoft.PowerShell.Commands.Remov \n",
      "   eItemCommand\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Delete the output folder if it already exists\n",
    "#!rm -f $PATH_METADATAS_URLS_DST # Linux\n",
    "!PowerShell.exe -Command \"Remove-Item -Path $PATH_METADATAS_URLS_DST -Recurse -Force\" # Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"categories\",    StringType(),  True),\n",
    "    StructField(\"channel_id\",    StringType(),  True),\n",
    "    StructField(\"crawl_date\",    DateType(),    True),\n",
    "    StructField(\"description\",   StringType(),  True),\n",
    "    StructField(\"dislike_count\", DoubleType(),  True), # This field must be specified as a double as it is represented as a floating point number\n",
    "    StructField(\"display_id\",    StringType(),  True),\n",
    "    StructField(\"duration\",      IntegerType(), True),\n",
    "    StructField(\"like_count\",    DoubleType(),  True), # This field must be specified as a double as it is represented as a floating point number\n",
    "    StructField(\"tags\",          StringType(),  True),\n",
    "    StructField(\"title\",         StringType(),  True),\n",
    "    StructField(\"upload_date\",   DateType(),    True),\n",
    "    StructField(\"view_count\",    DoubleType(),  True)  # This field must be specified as a double as it is represented as a floating point number\n",
    "])\n",
    "    \n",
    "metadatas = spark.read.json(PATH_METADATAS_SRC, schema=schema)\n",
    "\n",
    "# Cast the dislike_count, like_count and view_count to their respective integer type\n",
    "metadatas = metadatas \\\n",
    "    .withColumn(\"dislike_count\", metadatas.dislike_count.cast(IntegerType())) \\\n",
    "    .withColumn(\"like_count\", metadatas.like_count.cast(IntegerType())) \\\n",
    "    .withColumn(\"view_count\", metadatas.view_count.cast(LongType()))\n",
    "\n",
    "# Get urls and count of urls in the description\n",
    "get_urls_udf = udf(lambda x: get_urls(x), ArrayType(StringType()))\n",
    "metadatas = metadatas.withColumn('urls', get_urls_udf(col('description')))\n",
    "len_udf = udf(lambda x: len(x), IntegerType())\n",
    "metadatas = metadatas.withColumn('urls_count', len_udf(col('urls')))\n",
    "has_urls_udf = udf(lambda x: x > 0, BooleanType())\n",
    "metadatas = metadatas.withColumn('has_urls', has_urls_udf(col('urls_count')))\n",
    "\n",
    "# Drop the description and take only the videos with at least one url\n",
    "metadatas_urls = metadatas.drop('description')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+----------+\n",
      "| display_id|                urls|urls_count|\n",
      "+-----------+--------------------+----------+\n",
      "|VPqJmODeZyk|[https://goo.gl/J...|         1|\n",
      "|xLYGF-aCEHk|[https://goo.gl/J...|         1|\n",
      "|TqzfdwSZdRc|[https://goo.gl/J...|         1|\n",
      "|C-dn3p-ZTrM|[https://goo.gl/J...|         1|\n",
      "|OP_njme3T84|[https://goo.gl/J...|         1|\n",
      "+-----------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metadatas_urls.filter(metadatas_urls.has_urls).select('display_id', 'urls', 'urls_count').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+----------+\n",
      "| display_id|urls|urls_count|\n",
      "+-----------+----+----------+\n",
      "|SBqSc91Hn9g|  []|         0|\n",
      "|UuugEl86ESY|  []|         0|\n",
      "|oB4c-yvnbjs|  []|         0|\n",
      "|ZaV-gTCMV8E|  []|         0|\n",
      "|cGvL7AvMfM0|  []|         0|\n",
      "+-----------+----+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metadatas_urls.filter(~metadatas_urls.has_urls).select('display_id', 'urls', 'urls_count').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resolve Bitly URLs\n",
    "\n",
    "To further enrich our dataset, we write in a separate file all the Bitly URLs found in the dataset. We will then use various tools such as the Bitly API, or simple HTTP requests to resolve the URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_BITLY_URLS = '../data/generated/bitly_urls.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the output folder if it already exists\n",
    "#!rm -f $PATH_BITLY_URLS # Linux\n",
    "!PowerShell.exe -Command \"Remove-Item -Path $PATH_BITLY_URLS -Recurse -Force\" # Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitly_urls = metadatas_urls.select('display_id', explode('urls').alias('url'))\n",
    "bitly_urls = bitly_urls.filter(bitly_urls.url.like('%bit.ly%')).select('url').distinct()\n",
    "\n",
    "bitly_urls.write.csv(PATH_BITLY_URLS, sep='\\t', header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now assume that the **Bitly URLs have been resolved** and we can replace them by their corresponding URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_BITLY_RESOLVED_URLS = '../data/generated/bitly_resolved_urls.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_resolved_bitly_url(url, resolved_bitly_urls):\n",
    "    if url in resolved_bitly_urls:\n",
    "        return resolved_bitly_urls[url]\n",
    "    else:\n",
    "        return url\n",
    "\n",
    "\n",
    "\n",
    "def find_resolved_bitly_urls(urls, resolved_bitly_urls):\n",
    "    return [find_resolved_bitly_url(url, resolved_bitly_urls) for url in urls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the resolved bit.ly urls\n",
    "resolved_bitly_urls = {}\n",
    "with open(PATH_BITLY_RESOLVED_URLS, 'r') as f:\n",
    "    for line in f:\n",
    "        if line.startswith('bitly_url'):\n",
    "            continue # Skip header\n",
    "\n",
    "        bitly_url, long_url = line.strip().split('\\t')\n",
    "        if long_url is not None and long_url != '':\n",
    "            resolved_bitly_urls[bitly_url] = long_url\n",
    "\n",
    "print(f'Found {len(resolved_bitly_urls)} resolved bit.ly urls.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the resolved bit.ly urls\n",
    "find_resolved_bitly_urls_udf = udf(lambda x: find_resolved_bitly_urls(x, resolved_bitly_urls), ArrayType(StringType()))\n",
    "metadatas_urls = metadatas_urls.withColumn('resolved_urls', find_resolved_bitly_urls_udf(col('urls')))\n",
    "\n",
    "# Replace the old urls column with the new one\n",
    "metadatas_urls = metadatas_urls.drop('urls').withColumnRenamed('resolved_urls', 'urls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadatas_urls.select('display_id', 'urls', 'urls_count').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadatas_urls.write.parquet(PATH_METADATAS_URLS_DST, partitionBy=['has_urls'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('ada')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "93474a10e1612df951114730cd5f83d078f687a48e5e0a7160d033353df33aec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
