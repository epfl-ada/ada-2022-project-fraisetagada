{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process links in video descriptions\n",
    "\n",
    "This notebook processes links in video descriptions. The goal is to extract links that may be related to sponsors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import bs4\n",
    "import requests\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import dask.dataframe as dd\n",
    "from cachetools import cached, TTLCache\n",
    "\n",
    "from dask.diagnostics import ProgressBar\n",
    "ProgressBar().register()\n",
    "\n",
    "# Setup a cache for the requests\n",
    "cache = TTLCache(maxsize=1024, ttl=86400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_SUBDATASETS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../data/subdata/' if USE_SUBDATASETS else '../data/'\n",
    "\n",
    "PATH_METADATA_SRC = PATH + 'yt_metadata_en.jsonl.gz'\n",
    "PATH_SPONSORS_URLS_DST = '../data/generated/yt_sponsors_urls.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract links from video descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we extract links using regular expressions. We perform a first filtering to remove urls from sites that are generally not related to sponsors such as Youtube, Twitter, Facebook, Wikipedia, Discord, etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the invalid URLs\n",
    "PATH_INVALID_URLS = '../data/invalid_urls.csv'\n",
    "\n",
    "invalid_urls_reg = []\n",
    "with open(PATH_INVALID_URLS, 'r') as f:\n",
    "    for line in f:\n",
    "        invalid_urls_reg.append(fr\"(?i)({line.strip()})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_urls(description):\n",
    "    url_regex = r\"(https?:\\/\\/)?(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)\"\n",
    "    urls = []\n",
    "    for line in description.split(\"\\n\"):\n",
    "        if re.search(url_regex, line):\n",
    "            urlss = [x.group() for x in re.finditer(url_regex, line)] # Find all urls in the line\n",
    "            urlss = [x for x in urlss if not any([re.search(reg, x) for reg in invalid_urls_reg])] # Filter out invalid urls\n",
    "            urls.extend(urlss)\n",
    "    urls = set(urls) # Remove duplicates\n",
    "    return urls\n",
    "\n",
    "# Test the function on basic examples\n",
    "assert(not get_urls('There is no link.'))\n",
    "assert(get_urls('This is a link: www.special.com/') == {'www.special.com/'})\n",
    "assert(get_urls('This is a link: https://www.special.com/ and this is another link: https://www.youtube.com/watch?v=2') == {'https://www.special.com/'})\n",
    "assert(get_urls('This is a link: https://www.special.com/ \\n and this is another link: www.special.com/') == {'www.special.com/', 'https://www.special.com/'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "438it [2:50:35, 20.69s/it]"
     ]
    }
   ],
   "source": [
    "# Delete the destination file if it already exists\n",
    "if os.path.exists(PATH_SPONSORS_URLS_DST):\n",
    "    os.remove(PATH_SPONSORS_URLS_DST)\n",
    "\n",
    "for df_metadata in tqdm(pd.read_json(PATH_METADATA_SRC, compression=\"infer\", chunksize=100000, lines=True)):\n",
    "    # Get urls and count of urls in the description\n",
    "    df_metadata['urls'] = df_metadata['description'].apply(get_urls)\n",
    "    df_metadata['urls_cnt'] = df_metadata['urls'].apply(lambda x: len(x))\n",
    "\n",
    "    # Keep the sponsorized videos and their urls\n",
    "    sponsors = df_metadata[df_metadata['urls_cnt'] > 0][['display_id', 'urls', 'urls_cnt']]\n",
    "    \n",
    "    # Append to the file\n",
    "    sponsors.to_csv(PATH_SPONSORS_URLS_DST, mode='a', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resolve Bitly links (TODO)\n",
    "\n",
    "We resolve Bitly links to get the original url. This is done using the Bitly API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BITLY_API_KEY = '6eb2a9c9ec5950c276bf91b89ef2b1f229408807'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sponsors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cached(cache)\n",
    "def resolve_app_adjust_url(url, debug_mode=False):\n",
    "    if 'app.adjust.com' not in url:\n",
    "        return url\n",
    "    \n",
    "    if debug_mode: print(f'Resolving app adjust url: {url}')\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            soup = bs4.BeautifulSoup(response.text, 'html.parser')\n",
    "            new_url = soup.find('a', class_='product-header__title app-header__title')\n",
    "            if debug_mode: print(f'Resolved adjust.com url: {new_url}')\n",
    "            return new_url if new_url is not None else url\n",
    "        else:\n",
    "            if debug_mode: print(f'Could not resolve adjust.com url: {url}')\n",
    "            return url\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'Could not resolve url {url}: {e}')\n",
    "        return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cached(cache)\n",
    "def resolve_bit_ly_url(url, debug_mode=False):\n",
    "    if 'bit.ly' not in url:\n",
    "        return url\n",
    "\n",
    "    # Remove http:// or https:// from the url\n",
    "    url = url.replace('http://', '').replace('https://', '')\n",
    "\n",
    "    if debug_mode: print(f'Resolving bit.ly url {url}...')\n",
    "    try:\n",
    "        # Post a request via the bit.ly API\n",
    "        response = requests.post('https://api-ssl.bitly.com/v4/expand', headers={'Authorization': f'Bearer {BITLY_API_KEY}'}, json={'bitlink_id': url})\n",
    "\n",
    "        # Retrieve the long url from the response\n",
    "        if response.status_code == 200:\n",
    "            new_url = response.json()['long_url']\n",
    "            if debug_mode: print(f'\\tResolved bit.ly url: {url} -> {new_url}')\n",
    "\n",
    "            #if re.search(r\"app.adjust.com\", new_url):\n",
    "            #    return resolve_app_adjust_url(new_url)\n",
    "                    \n",
    "            return new_url\n",
    "        else:\n",
    "            if debug_mode: print(f'\\tCould not resolve bit.ly url: {url}, status code: {response.status_code}')\n",
    "            return url\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'Could not resolve url {url}: {e}')\n",
    "        return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('ada')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "93474a10e1612df951114730cd5f83d078f687a48e5e0a7160d033353df33aec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
