{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate parquet datasets from original datasets\n",
    "\n",
    "This notebook generates parquet datasets from original datasets, which ar stored in the data folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Cours\\EPFL\\IN Master 1\\Applied Data Analysis [CS401]\\Project\\processing\\generate_datasets.ipynb Cellule 2\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Cours/EPFL/IN%20Master%201/Applied%20Data%20Analysis%20%5BCS401%5D/Project/processing/generate_datasets.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Cours/EPFL/IN%20Master%201/Applied%20Data%20Analysis%20%5BCS401%5D/Project/processing/generate_datasets.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mdask\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdataframe\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mdd\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Cours/EPFL/IN%20Master%201/Applied%20Data%20Analysis%20%5BCS401%5D/Project/processing/generate_datasets.ipynb#W1sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdask\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdiagnostics\u001b[39;00m \u001b[39mimport\u001b[39;00m ProgressBar\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Cours/EPFL/IN%20Master%201/Applied%20Data%20Analysis%20%5BCS401%5D/Project/processing/generate_datasets.ipynb#W1sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m ProgressBar()\u001b[39m.\u001b[39mregister()\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\ada\\lib\\site-packages\\dask\\__init__.py:3\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m config, datasets\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_version\u001b[39;00m \u001b[39mimport\u001b[39;00m get_versions\n\u001b[1;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m \u001b[39mimport\u001b[39;00m annotate, compute, is_dask_collection, optimize, persist, visualize\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m istask\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdelayed\u001b[39;00m \u001b[39mimport\u001b[39;00m delayed\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:986\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:680\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:846\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:941\u001b[0m, in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1039\u001b[0m, in \u001b[0;36mget_data\u001b[1;34m(self, path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "\n",
    "from dask.diagnostics import ProgressBar\n",
    "ProgressBar().register()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METADATA_BLOCKSIZE = 2**27 # 128 MB\n",
    "\n",
    "PATH_DATA = '../data/'\n",
    "\n",
    "PATH_METADATA_SRC  = PATH_DATA + 'yt_metadata_en.jsonl'\n",
    "PATH_METADATA_DST  = PATH_DATA + 'yt_metadata_en.parquet/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cull_empty_partitions(df):\n",
    "    ll = list(df.map_partitions(len).compute())\n",
    "    df_delayed = df.to_delayed()\n",
    "    df_delayed_new = list()\n",
    "    pempty = None\n",
    "    for ix, n in enumerate(ll):\n",
    "        if 0 == n:\n",
    "            pempty = df.get_partition(ix)\n",
    "        else:\n",
    "            df_delayed_new.append(df_delayed[ix])\n",
    "    if pempty is not None:\n",
    "        df = dd.from_delayed(df_delayed_new, meta=pempty)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = {\n",
    "    'categories'    : 'str',\n",
    "    'channel_id'    : 'str',\n",
    "    'crawl_date'    : 'str',\n",
    "    'description'   : 'str',\n",
    "    'dislike_count' : 'int32',\n",
    "    'display_id'    : 'str',\n",
    "    'duration'      : 'int32',\n",
    "    'like_count'    : 'int32',\n",
    "    'tags'          : 'str',\n",
    "    'title'         : 'str',\n",
    "    'upload_date'   : 'str',\n",
    "    'view_count'    : 'int32'\n",
    "}\n",
    "df = dd.read_json(PATH_METADATA_SRC, lines=True, blocksize=METADATA_BLOCKSIZE, dtype=dtype, convert_dates=['crawl_date', 'upload_date'])\n",
    "df['categories'] = df['categories'].astype('category')\n",
    "df = cull_empty_partitions(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(PATH_METADATA_DST, engine='pyarrow', compression='snappy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('ada')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "93474a10e1612df951114730cd5f83d078f687a48e5e0a7160d033353df33aec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
