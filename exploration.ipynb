{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.font_manager as font_manager\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.ticker as mtick\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "#fontpath = os.path.expanduser('~/.local/share/fonts/LinLibertine_DRah.ttf')\n",
    "#prop = font_manager.FontProperties(fname=fontpath)\n",
    "\n",
    "params = {\n",
    "    \"axes.titlesize\" : 14,\n",
    "    'axes.labelsize': 12,\n",
    "    'font.size': 12,\n",
    "    'legend.fontsize': 12,\n",
    "    'xtick.labelsize': 12,\n",
    "    'ytick.labelsize': 12,\n",
    "    #'font.family': prop.get_name(),\n",
    "    'text.usetex': True\n",
    "}\n",
    "\n",
    "mpl.rcParams.update(params)\n",
    "\n",
    "import sys\n",
    "# Local Modules\n",
    "sys.path.insert(0, os.path.abspath('/scratch/horta/youtube_dataset/'))\n",
    "#from helpers.plot import set_size\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loads data and preprocess datetime fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "read_csv() got an unexpected keyword argument 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [34], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_sb_f \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39m./data/df_timeseries_en.tsv.gz\u001b[39m\u001b[39m\"\u001b[39m, compression\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minfer\u001b[39m\u001b[39m\"\u001b[39m, sep\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m, columns\u001b[39m=\u001b[39m[\u001b[39m3\u001b[39m])\n\u001b[0;32m      2\u001b[0m df_sb_f[\u001b[39m\"\u001b[39m\u001b[39mdatetime\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_datetime(df_sb_f[\u001b[39m\"\u001b[39m\u001b[39mdatetime\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\arnau\\anaconda3\\envs\\ada\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[1;31mTypeError\u001b[0m: read_csv() got an unexpected keyword argument 'columns'"
     ]
    }
   ],
   "source": [
    "df_sb_f = pd.read_csv(\"./data/df_timeseries_en.tsv.gz\", compression=\"infer\", sep=\"\\t\")\n",
    "df_sb_f[\"datetime\"] = pd.to_datetime(df_sb_f[\"datetime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel</th>\n",
       "      <th>category</th>\n",
       "      <th>datetime</th>\n",
       "      <th>views</th>\n",
       "      <th>delta_views</th>\n",
       "      <th>subs</th>\n",
       "      <th>delta_subs</th>\n",
       "      <th>videos</th>\n",
       "      <th>delta_videos</th>\n",
       "      <th>activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UCBJuEqXfXTdcPSbGO9qqn1g</td>\n",
       "      <td>Film and Animation</td>\n",
       "      <td>2017-07-03</td>\n",
       "      <td>2.024946e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>650.222222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UCBJuEqXfXTdcPSbGO9qqn1g</td>\n",
       "      <td>Film and Animation</td>\n",
       "      <td>2017-07-10</td>\n",
       "      <td>3.940857e+05</td>\n",
       "      <td>191591.111111</td>\n",
       "      <td>1046.000000</td>\n",
       "      <td>395.777778</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UCBJuEqXfXTdcPSbGO9qqn1g</td>\n",
       "      <td>Film and Animation</td>\n",
       "      <td>2017-07-17</td>\n",
       "      <td>8.353938e+05</td>\n",
       "      <td>441308.083333</td>\n",
       "      <td>1501.500000</td>\n",
       "      <td>455.500000</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UCBJuEqXfXTdcPSbGO9qqn1g</td>\n",
       "      <td>Film and Animation</td>\n",
       "      <td>2017-07-24</td>\n",
       "      <td>1.104577e+06</td>\n",
       "      <td>269183.250000</td>\n",
       "      <td>1750.000000</td>\n",
       "      <td>248.500000</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UCBJuEqXfXTdcPSbGO9qqn1g</td>\n",
       "      <td>Film and Animation</td>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>1.284406e+06</td>\n",
       "      <td>179828.600000</td>\n",
       "      <td>2008.300000</td>\n",
       "      <td>258.300000</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18872494</th>\n",
       "      <td>UC0UeVA9YHpOEr_Ng442xiRw</td>\n",
       "      <td>Gaming</td>\n",
       "      <td>2019-09-02</td>\n",
       "      <td>6.012938e+06</td>\n",
       "      <td>232418.277778</td>\n",
       "      <td>61268.611111</td>\n",
       "      <td>1305.611111</td>\n",
       "      <td>278</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18872495</th>\n",
       "      <td>UC0UeVA9YHpOEr_Ng442xiRw</td>\n",
       "      <td>Gaming</td>\n",
       "      <td>2019-09-09</td>\n",
       "      <td>6.244579e+06</td>\n",
       "      <td>231640.888889</td>\n",
       "      <td>62631.666667</td>\n",
       "      <td>1363.055556</td>\n",
       "      <td>287</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18872496</th>\n",
       "      <td>UC0UeVA9YHpOEr_Ng442xiRw</td>\n",
       "      <td>Gaming</td>\n",
       "      <td>2019-09-16</td>\n",
       "      <td>6.480902e+06</td>\n",
       "      <td>236322.933333</td>\n",
       "      <td>64010.000000</td>\n",
       "      <td>1378.333333</td>\n",
       "      <td>294</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18872497</th>\n",
       "      <td>UC0UeVA9YHpOEr_Ng442xiRw</td>\n",
       "      <td>Gaming</td>\n",
       "      <td>2019-09-23</td>\n",
       "      <td>6.745317e+06</td>\n",
       "      <td>264415.200000</td>\n",
       "      <td>65480.000000</td>\n",
       "      <td>1470.000000</td>\n",
       "      <td>301</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18872498</th>\n",
       "      <td>UC0UeVA9YHpOEr_Ng442xiRw</td>\n",
       "      <td>Gaming</td>\n",
       "      <td>2019-09-30</td>\n",
       "      <td>6.987738e+06</td>\n",
       "      <td>242420.771429</td>\n",
       "      <td>66542.857143</td>\n",
       "      <td>1062.857143</td>\n",
       "      <td>308</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18872499 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           channel            category   datetime  \\\n",
       "0         UCBJuEqXfXTdcPSbGO9qqn1g  Film and Animation 2017-07-03   \n",
       "1         UCBJuEqXfXTdcPSbGO9qqn1g  Film and Animation 2017-07-10   \n",
       "2         UCBJuEqXfXTdcPSbGO9qqn1g  Film and Animation 2017-07-17   \n",
       "3         UCBJuEqXfXTdcPSbGO9qqn1g  Film and Animation 2017-07-24   \n",
       "4         UCBJuEqXfXTdcPSbGO9qqn1g  Film and Animation 2017-07-31   \n",
       "...                            ...                 ...        ...   \n",
       "18872494  UC0UeVA9YHpOEr_Ng442xiRw              Gaming 2019-09-02   \n",
       "18872495  UC0UeVA9YHpOEr_Ng442xiRw              Gaming 2019-09-09   \n",
       "18872496  UC0UeVA9YHpOEr_Ng442xiRw              Gaming 2019-09-16   \n",
       "18872497  UC0UeVA9YHpOEr_Ng442xiRw              Gaming 2019-09-23   \n",
       "18872498  UC0UeVA9YHpOEr_Ng442xiRw              Gaming 2019-09-30   \n",
       "\n",
       "                 views    delta_views          subs   delta_subs  videos  \\\n",
       "0         2.024946e+05       0.000000    650.222222     0.000000       5   \n",
       "1         3.940857e+05  191591.111111   1046.000000   395.777778       6   \n",
       "2         8.353938e+05  441308.083333   1501.500000   455.500000       6   \n",
       "3         1.104577e+06  269183.250000   1750.000000   248.500000       6   \n",
       "4         1.284406e+06  179828.600000   2008.300000   258.300000       6   \n",
       "...                ...            ...           ...          ...     ...   \n",
       "18872494  6.012938e+06  232418.277778  61268.611111  1305.611111     278   \n",
       "18872495  6.244579e+06  231640.888889  62631.666667  1363.055556     287   \n",
       "18872496  6.480902e+06  236322.933333  64010.000000  1378.333333     294   \n",
       "18872497  6.745317e+06  264415.200000  65480.000000  1470.000000     301   \n",
       "18872498  6.987738e+06  242420.771429  66542.857143  1062.857143     308   \n",
       "\n",
       "          delta_videos  activity  \n",
       "0                    0         3  \n",
       "1                    1         1  \n",
       "2                    0         1  \n",
       "3                    0         0  \n",
       "4                    0         0  \n",
       "...                ...       ...  \n",
       "18872494             2        10  \n",
       "18872495             9        13  \n",
       "18872496             7        16  \n",
       "18872497             7        15  \n",
       "18872498             7        16  \n",
       "\n",
       "[18872499 rows x 10 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_sb_f (18'872'498 x )\n",
    "# 0: channel\n",
    "# 1: category\n",
    "# 2: datetime\n",
    "# 3: views\n",
    "# 4: delta_views\n",
    "# 5: subs\n",
    "# 6: delta_subs\n",
    "# 7: videos\n",
    "# 8: activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ArrowMemoryError",
     "evalue": "malloc of size 4294967296 failed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mArrowMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_vd_f \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_feather(\u001b[39m\"\u001b[39m\u001b[39m./data/yt_metadata_helper.feather\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m df_vd_f[\u001b[39m\"\u001b[39m\u001b[39mdummmy\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\arnau\\anaconda3\\envs\\ada\\lib\\site-packages\\pandas\\io\\feather_format.py:132\u001b[0m, in \u001b[0;36mread_feather\u001b[1;34m(path, columns, use_threads, storage_options)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpyarrow\u001b[39;00m \u001b[39mimport\u001b[39;00m feather\n\u001b[0;32m    128\u001b[0m \u001b[39mwith\u001b[39;00m get_handle(\n\u001b[0;32m    129\u001b[0m     path, \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m, storage_options\u001b[39m=\u001b[39mstorage_options, is_text\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    130\u001b[0m ) \u001b[39mas\u001b[39;00m handles:\n\u001b[1;32m--> 132\u001b[0m     \u001b[39mreturn\u001b[39;00m feather\u001b[39m.\u001b[39;49mread_feather(\n\u001b[0;32m    133\u001b[0m         handles\u001b[39m.\u001b[39;49mhandle, columns\u001b[39m=\u001b[39;49mcolumns, use_threads\u001b[39m=\u001b[39;49m\u001b[39mbool\u001b[39;49m(use_threads)\n\u001b[0;32m    134\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\arnau\\anaconda3\\envs\\ada\\lib\\site-packages\\pyarrow\\feather.py:231\u001b[0m, in \u001b[0;36mread_feather\u001b[1;34m(source, columns, use_threads, memory_map)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    209\u001b[0m \u001b[39mRead a pandas.DataFrame from Feather format. To read as pyarrow.Table use\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \u001b[39mfeather.read_table.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[39mdf : pandas.DataFrame\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    230\u001b[0m _check_pandas_version()\n\u001b[1;32m--> 231\u001b[0m \u001b[39mreturn\u001b[39;00m (read_table(\n\u001b[0;32m    232\u001b[0m     source, columns\u001b[39m=\u001b[39;49mcolumns, memory_map\u001b[39m=\u001b[39;49mmemory_map,\n\u001b[0;32m    233\u001b[0m     use_threads\u001b[39m=\u001b[39;49muse_threads)\u001b[39m.\u001b[39;49mto_pandas(use_threads\u001b[39m=\u001b[39;49muse_threads))\n",
      "File \u001b[1;32mc:\\Users\\arnau\\anaconda3\\envs\\ada\\lib\\site-packages\\pyarrow\\array.pxi:823\u001b[0m, in \u001b[0;36mpyarrow.lib._PandasConvertible.to_pandas\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\arnau\\anaconda3\\envs\\ada\\lib\\site-packages\\pyarrow\\table.pxi:3913\u001b[0m, in \u001b[0;36mpyarrow.lib.Table._to_pandas\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\arnau\\anaconda3\\envs\\ada\\lib\\site-packages\\pyarrow\\pandas_compat.py:818\u001b[0m, in \u001b[0;36mtable_to_blockmanager\u001b[1;34m(options, table, categories, ignore_metadata, types_mapper)\u001b[0m\n\u001b[0;32m    816\u001b[0m _check_data_column_metadata_consistency(all_columns)\n\u001b[0;32m    817\u001b[0m columns \u001b[39m=\u001b[39m _deserialize_column_index(table, all_columns, column_indexes)\n\u001b[1;32m--> 818\u001b[0m blocks \u001b[39m=\u001b[39m _table_to_blocks(options, table, categories, ext_columns_dtypes)\n\u001b[0;32m    820\u001b[0m axes \u001b[39m=\u001b[39m [columns, index]\n\u001b[0;32m    821\u001b[0m \u001b[39mreturn\u001b[39;00m BlockManager(blocks, axes)\n",
      "File \u001b[1;32mc:\\Users\\arnau\\anaconda3\\envs\\ada\\lib\\site-packages\\pyarrow\\pandas_compat.py:1168\u001b[0m, in \u001b[0;36m_table_to_blocks\u001b[1;34m(options, block_table, categories, extension_columns)\u001b[0m\n\u001b[0;32m   1163\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_table_to_blocks\u001b[39m(options, block_table, categories, extension_columns):\n\u001b[0;32m   1164\u001b[0m     \u001b[39m# Part of table_to_blockmanager\u001b[39;00m\n\u001b[0;32m   1165\u001b[0m \n\u001b[0;32m   1166\u001b[0m     \u001b[39m# Convert an arrow table to Block from the internal pandas API\u001b[39;00m\n\u001b[0;32m   1167\u001b[0m     columns \u001b[39m=\u001b[39m block_table\u001b[39m.\u001b[39mcolumn_names\n\u001b[1;32m-> 1168\u001b[0m     result \u001b[39m=\u001b[39m pa\u001b[39m.\u001b[39;49mlib\u001b[39m.\u001b[39;49mtable_to_blocks(options, block_table, categories,\n\u001b[0;32m   1169\u001b[0m                                     \u001b[39mlist\u001b[39;49m(extension_columns\u001b[39m.\u001b[39;49mkeys()))\n\u001b[0;32m   1170\u001b[0m     \u001b[39mreturn\u001b[39;00m [_reconstruct_block(item, columns, extension_columns)\n\u001b[0;32m   1171\u001b[0m             \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m result]\n",
      "File \u001b[1;32mc:\\Users\\arnau\\anaconda3\\envs\\ada\\lib\\site-packages\\pyarrow\\table.pxi:2602\u001b[0m, in \u001b[0;36mpyarrow.lib.table_to_blocks\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\arnau\\anaconda3\\envs\\ada\\lib\\site-packages\\pyarrow\\error.pxi:117\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mArrowMemoryError\u001b[0m: malloc of size 4294967296 failed"
     ]
    }
   ],
   "source": [
    "df_vd_f = pd.read_feather(\"./data/yt_metadata_helper.feather\")\n",
    "df_vd_f[\"dummmy\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>view_count</th>\n",
       "      <th>dummmy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1057.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12894.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1800602.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57640.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>86368.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72924789</th>\n",
       "      <td>4409.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72924790</th>\n",
       "      <td>1172.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72924791</th>\n",
       "      <td>1898.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72924792</th>\n",
       "      <td>726.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72924793</th>\n",
       "      <td>37572.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72924794 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          view_count  dummmy\n",
       "0             1057.0       1\n",
       "1            12894.0       1\n",
       "2          1800602.0       1\n",
       "3            57640.0       1\n",
       "4            86368.0       1\n",
       "...              ...     ...\n",
       "72924789      4409.0       1\n",
       "72924790      1172.0       1\n",
       "72924791      1898.0       1\n",
       "72924792       726.0       1\n",
       "72924793     37572.0       1\n",
       "\n",
       "[72924794 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_vd_f (72'924'794 x 8)\n",
    "# 0: categories\n",
    "# 1: channel_id\n",
    "# 2: dislike_count\n",
    "# 3: display_id\n",
    "# 4: duration\n",
    "# 5: like_count\n",
    "# 6: upload_date\n",
    "# 7: view_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ch_f = pd.read_csv(\"./data/df_channels_en.tsv.gz\", compression=\"infer\", sep=\"\\t\")\n",
    "df_ch_f[\"join_date\"] = pd.to_datetime(df_ch_f[\"join_date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_comments = pd.read_csv(\"./data/num_comments.tsv.gz\", compression=\"infer\", sep=\"\\t\")\n",
    "num_comments_authors = pd.read_csv(\"./data/num_comments_authors.tsv.gz\", compression=\"infer\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Video and channel statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gets videos_yt count\n",
    "df_vd_vid_count = dict(df_vd_f.groupby(\"channel_id\").count().display_id) \n",
    "df_ch_f[\"videos_yt\"] = df_ch_f[\"channel\"].apply(lambda x: df_vd_vid_count[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.transforms as transforms\n",
    "\n",
    "fig, axs = plt.subplots(5, 5, figsize=(14, 6), \n",
    "                         gridspec_kw={\"wspace\": 0.25, \"hspace\": 0.1, \n",
    "                                      \"height_ratios\": [0.2, 0.8, 0.65, 0.2, 0.8]})\n",
    "N = len(df_vd_f)#136470\n",
    "    \n",
    "kwargs = {'cumulative': False}\n",
    "\n",
    "def plot_mean(ax, vals):\n",
    "    trans = transforms.blended_transform_factory(ax.transData, ax.transAxes)\n",
    "    trans = transforms.blended_transform_factory(ax.transData, ax.transAxes)\n",
    "    quant95 = vals.quantile(0.95)\n",
    "    quant100 = vals.quantile(1)\n",
    "    plt.plot([np.log10(quant95), np.log10(quant100)], [1.15, 1.15], \n",
    "             lw=1, color = \"black\", transform=trans, clip_on=False)\n",
    "    top5p = vals[vals >= quant95].sum() / sum(vals)\n",
    "    plt.text((np.log10(quant95) + np.log10(quant100)) / 2, 1.25, \n",
    "             \"Top $5\\% = {}\\%$\".format(round(top5p*100,1)), ha=\"center\",\n",
    "        transform=trans, size=10)\n",
    "\n",
    "def plot_box(ax, vals):\n",
    "    trans = transforms.blended_transform_factory(ax.transData, ax.transAxes)\n",
    "    ax.boxplot(np.log10(vals), showfliers=False, vert=False)\n",
    "    ax.set_yticks([])\n",
    "    \n",
    "# Video stuff\n",
    "df_tmp = df_vd_f.sample(N)\n",
    "titles = [\"Views\", \"Likes\", \"Dislikes\", \"Duration\"]\n",
    "cols = [\"view_count\", \"like_count\", \"dislike_count\", \"duration\"]\n",
    "xlabels = [r'$\\log_{10}(views + 1)$', r'$\\log_{10}(likes + 1)$',\n",
    "          r'$\\log_{10}(dislikes + 1)$', r'$\\log_{10}(duration)$ (in seconds)']\n",
    "xticks = [[0, 2, 4, 6, 8], [0, 2, 4], [0, 2, 4], [0, 1, 2, 3, 4, 5]]\n",
    "\n",
    "for idx, title in enumerate(titles):\n",
    "    ax = axs[1, idx]\n",
    "    sns.distplot(np.log10(df_tmp[cols[idx]] + 1), hist_kws=kwargs, kde=False, kde_kws=kwargs, ax=ax, norm_hist=True)\n",
    "    ax.set_xlabel(xlabels[idx])\n",
    "    ax.set_xticks(xticks[idx])\n",
    "    xtickstmp = ax.get_xticks()\n",
    "    xlimtmp = ax.get_xlim()\n",
    "    \n",
    "    ax = axs[0, idx]\n",
    "    ax.set_title(title, pad=25, size=16)\n",
    "    vals = df_tmp[cols[idx]].dropna() + 1\n",
    "    plot_box(ax, vals)\n",
    "    plot_mean(ax, vals)\n",
    "    ax.set_xticks(xtickstmp)\n",
    "    ax.set_xlim(xlimtmp)\n",
    "    \n",
    "# Channel stuff\n",
    "df_tmp = df_ch_f\n",
    "titles = [\"Videos per channel\", \"Subscribers per channel\"]\n",
    "cols = [\"videos_yt\", \"subscribers_cc\"]\n",
    "xlabels = [r'$\\log_{10}(\\#videos)$', \n",
    "           r'$\\log_{10}(\\#subscribers)$']\n",
    "\n",
    "for idx, title in enumerate(titles):\n",
    "    \n",
    "    ax = axs[4, idx]\n",
    "    sns.distplot(np.log10(df_tmp[cols[idx]] + 1), hist_kws=kwargs, kde=False, kde_kws=kwargs, ax=ax, norm_hist=True)\n",
    "    ax.set_xlabel(xlabels[idx])\n",
    "    xtickstmp = ax.get_xticks()\n",
    "    xlimtmp = ax.get_xlim()\n",
    "    \n",
    "    ax = axs[3, idx]\n",
    "    ax.set_title(title, pad=25, size=16)\n",
    "    vals = df_tmp[cols[idx]].dropna() + 1\n",
    "    plot_box(ax, vals)\n",
    "    plot_mean(ax, vals)\n",
    "    ax.set_xticks(xtickstmp)\n",
    "    ax.set_xlim(xlimtmp)\n",
    "\n",
    "N = len(df_sb_f)#136470\n",
    "\n",
    "# Time series stuff\n",
    "df_tmp = df_sb_f.sample(N)\n",
    "titles = [\"Weekly views gain\", \"Weekly subscriber gain\"]\n",
    "cols = [\"delta_views\", \"delta_subs\"]\n",
    "xlabels = [r'$\\log_{10}(\\Delta views + 1)$', \n",
    "           r'$\\log_{10}(\\Delta subscribers + 1)$']\n",
    "\n",
    "for idx, title in enumerate(titles):\n",
    "    ax = axs[4, idx+2]\n",
    "    sns.distplot(np.log10(df_tmp[cols[idx]] + 1), hist_kws=kwargs, \n",
    "                 kde=False, kde_kws=kwargs, ax=ax, norm_hist=True)\n",
    "    ax.set_xlabel(xlabels[idx])\n",
    "    xtickstmp = ax.get_xticks()\n",
    "    xlimtmp = ax.get_xlim()\n",
    "    \n",
    "    ax = axs[3, idx+2]\n",
    "    ax.set_title(title, pad=25, size=16)\n",
    "    vals = df_tmp[cols[idx]].dropna() + 1\n",
    "    plot_box(ax, vals)\n",
    "    plot_mean(ax, vals)\n",
    "    ax.set_xticks(xtickstmp)\n",
    "    ax.set_xlim(xlimtmp)\n",
    "    \n",
    "for ax in axs[2, :]:\n",
    "    ax.set_visible(False)\n",
    "\n",
    "\n",
    "for ax in axs[0:2, 4]:\n",
    "    ax.set_xticks([0, 2, 4, 6])\n",
    "    ax.set_xlim([0, 7])\n",
    "    \n",
    "for ax in axs[3:, 4]:\n",
    "    ax.set_xticks([0, 2, 4, 6])\n",
    "    ax.set_xlim([0, 7])\n",
    "    \n",
    "NC = 1000000000\n",
    "    \n",
    "sns.distplot(np.log10(num_comments.num_comms.head(NC) + 1), kde=False, \n",
    "             kde_kws=kwargs, ax=axs[1, 4], norm_hist=True)\n",
    "sns.distplot(np.log10(num_comments_authors.video_id.head(NC) + 1), kde=False, \n",
    "             kde_kws=kwargs,  ax=axs[4, 4], norm_hist=True)\n",
    "\n",
    "# # axs[0, 0].set_title(\"Commments per Video\", pad=25, size=16)\n",
    "# # axs[0, 1].set_title(\"Commments per Author\", pad=25, size=16)\n",
    "\n",
    "ax = axs[0, 4]\n",
    "ax.set_title(\"Commments per Video\", pad=25, size=16)\n",
    "vals = num_comments.num_comms.head(NC) + 1\n",
    "plot_box(ax, vals)\n",
    "plot_mean(ax, vals)\n",
    "ax.set_xticks([])\n",
    "\n",
    "\n",
    "ax = axs[3, 4]\n",
    "ax.set_title(\"Commments per User\", pad=25, size=16)\n",
    "vals = num_comments_authors.video_id.head(NC) + 1\n",
    "plot_box(ax, vals)\n",
    "plot_mean(ax, vals)\n",
    "ax.set_xticks([])\n",
    "\n",
    "axs[1, 4].set_yscale(\"log\")\n",
    "axs[4, 4].set_yscale(\"log\")\n",
    "\n",
    "\n",
    "axs[1, 4].set_xlabel(r'$\\log_{10}(\\#comments + 1)$')\n",
    "axs[4, 4].set_xlabel(r'$\\log_{10}(\\#comments + 1)$')\n",
    "\n",
    "set_size(fig, size=(14, 6))\n",
    "fig.savefig(\"./images/video_metadata.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Time series examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.dates as mdates\n",
    "years = mdates.YearLocator()   # every year\n",
    "months = mdates.MonthLocator()  # every month\n",
    "years_fmt = mdates.DateFormatter('%Y')\n",
    "fig, axs = plt.subplots(1, 3, figsize=(7, 2.5), sharey=True, sharex=True, gridspec_kw={\"wspace\": 0.05,})\n",
    "np.random.seed(5)\n",
    "s = df_sb_f.sample(3).channel.values\n",
    "for chan, ax in zip(s, axs):\n",
    "    vals = df_sb_f.loc[df_sb_f.channel == chan]\n",
    "    vals.datetime = pd.to_datetime(vals.datetime)\n",
    "    ax.plot(vals.datetime, vals.views, label=\"Cum. Views\", color=\"#1b9e77\")\n",
    "    ax.plot(vals.datetime, vals.subs, label=\"Cum. Subscribers\", color=\"#7570b3\", ls=\"--\")\n",
    "    ax.plot(vals.datetime, vals.videos, label=\"Cum. Videos\", color=\"#e6ab02\", ls=\"-.\")\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_xlabel(\"Date\")\n",
    "    ax.xaxis.grid(color=\"#CCCCCC\", ls=\":\")\n",
    "    ax.yaxis.grid(color=\"#CCCCCC\", ls=\":\")\n",
    "\n",
    "axs[1].legend(bbox_to_anchor=(0.5, 1.3), ncol=3, loc='upper center')\n",
    "ax.xaxis.set_major_locator(years)\n",
    "ax.xaxis.set_major_formatter(years_fmt)\n",
    "ax.xaxis.set_minor_locator(months)\n",
    "\n",
    "set_size(fig, size=(7, 3))\n",
    "fig.savefig(\"./images/example_ts.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Time series completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sb_sum = df_sb_f.groupby(pd.Grouper(key=\"datetime\", freq=\"M\")).agg({\"channel\": pd.Series.nunique})\n",
    "df_sb_sum = df_sb_sum.head(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ch_sum = df_ch_f.groupby(pd.Grouper(key=\"join_date\", freq=\"M\")).channel.count()\n",
    "df_ch_sum = df_ch_sum.cumsum()\n",
    "df_ch_sum = df_ch_sum[df_sb_sum.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(7,3), sharey=True, sharex=True,\n",
    "                       gridspec_kw={\"wspace\": 0.05})\n",
    "ax.plot(df_sb_sum.channel /df_ch_sum, color=\"#1b9e77\")\n",
    "ax.yaxis.set_major_formatter(mtick.PercentFormatter(xmax=1))\n",
    "ax.xaxis.set_major_locator(years)\n",
    "ax.xaxis.set_major_formatter(years_fmt)\n",
    "ax.xaxis.set_minor_locator(months)\n",
    "ax.xaxis.grid(color=\"#CCCCCC\", ls=\":\")\n",
    "ax.yaxis.grid(color=\"#CCCCCC\", ls=\":\")\n",
    "ax.set_xlabel(\"Date\")\n",
    "ax.set_ylabel(\"\\% of channels with timeseries\")\n",
    "set_size(fig, size=(7, 3))\n",
    "fig.savefig(\"./images/repr_ts.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Creation date for channels and videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ch_count = df_ch_f.groupby(pd.Grouper(key=\"join_date\", freq=\"M\")).count().videos_cc\n",
    "df_vc_count = df_vd_f.groupby(pd.Grouper(key=\"upload_date\", freq=\"M\")).count().channel_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = mdates.YearLocator(4)   # every 2 years\n",
    "months = mdates.YearLocator(2)  # every year\n",
    "fig, axs = plt.subplots(1, 2, figsize=(7,3), sharex=True, gridspec_kw={\"wspace\": 0.20})\n",
    "\n",
    "ax = axs[0]\n",
    "ax.plot(df_ch_count.cumsum(),  color=\"#1b9e77\", label=\"\\% channels created\")\n",
    "ax.plot(df_vc_count.cumsum(),  color=\"#7570b3\", ls=\"--\", label=\"\\% videos uploaded\")\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_title(\"Cumulative count\")\n",
    "ax = axs[1]\n",
    "ax.plot(df_ch_count.cumsum()/136470,  color=\"#1b9e77\", label=\"\\% channels created\")\n",
    "ax.plot(df_vc_count.cumsum()/72924794,  color=\"#7570b3\", ls=\"--\", label=\"\\% videos uploaded\")\n",
    "ax.yaxis.set_major_formatter(mtick.PercentFormatter(xmax=1))\n",
    "ax.set_title(\"Cumulative percentage\")\n",
    "\n",
    "for ax in axs:\n",
    "    ax.xaxis.set_major_locator(years)\n",
    "    ax.xaxis.set_major_formatter(years_fmt)\n",
    "    ax.xaxis.set_minor_locator(months)\n",
    "    ax.xaxis.grid(color=\"#CCCCCC\", ls=\":\")\n",
    "    ax.yaxis.grid(color=\"#CCCCCC\", ls=\":\")\n",
    "    ax.set_xlabel(\"Date\")\n",
    "\n",
    "axs[0].legend(bbox_to_anchor=(1.15, 1.5), ncol=3, loc='upper center')\n",
    "set_size(fig, size=(7, 3))\n",
    "fig.savefig(\"./images/overall_ch.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Ranking completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "fig, axs = plt.subplots(1, 2, figsize=(14, 3), sharex=True, gridspec_kw={\"wspace\": 0.30})\n",
    " \n",
    "\n",
    "ax = axs[0]\n",
    "\n",
    "ranks = df_ch_f[\"subscriber_rank_sb\"].dropna().sort_values().values\n",
    "quant = np.array(list(range(1,len(ranks)+ 1)))\n",
    "p = quant / ranks\n",
    "\n",
    "ax.plot(ranks, p)#, s=10, alpha=1)\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_ylabel(\"Percent in the sample\")\n",
    "ax.set_xlabel(\"Subscriber rank\")\n",
    "ax.set_title(\"Cumulative percentage of\\nchannels in sample\")\n",
    "ax.xaxis.grid(color=\"#CCCCCC\", ls=\":\")\n",
    "ax.yaxis.grid(color=\"#CCCCCC\", ls=\":\")\n",
    "ax.set_xticks([10**1, 10**2, 10**3, 10**4, 10**5, 10**6])\n",
    "\n",
    "ax = axs[1]\n",
    "sns.histplot(\n",
    "    df_ch_f, x=\"subscriber_rank_sb\", y=\"subscribers_cc\",\n",
    "    bins=30, discrete=(False, False), log_scale=(True, True),\n",
    "    cbar=True, cbar_kws=dict(shrink=.75),\n",
    ")\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_xlabel(\"Subscriber rank\")\n",
    "ax.set_ylabel(\"Number of subscribers ($\\log$)\")\n",
    "ax.xaxis.grid(color=\"#CCCCCC\", ls=\":\")\n",
    "ax.yaxis.grid(color=\"#CCCCCC\", ls=\":\")\n",
    "ax.set_title(r'Subscriber rank vs. $\\log(\\#subscribers)$' + \"\\n\" + r'($\\rho = -0.994^{***}$)')\n",
    "print(stats.spearmanr(df_ch_f[~df_ch_f[\"subscriber_rank_sb\"].isna()][\"subscriber_rank_sb\"], \n",
    "                df_ch_f[~df_ch_f[\"subscriber_rank_sb\"].isna()][\"subscribers_cc\"]))\n",
    "ax.set_yticks([10**4, 10**5, 10**6, 10**7, 10**8])\n",
    "ax.set_xticks([10**1, 10**2, 10**3, 10**4, 10**5, 10**6])\n",
    "\n",
    "set_size(fig, size=(7, 3))\n",
    "fig.savefig(\"./images/ranking.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 1: Views, Videos, Likes, Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vd_cat_count = df_vd_f.groupby(\"categories\").sum()\n",
    "df_vd_cat_count = df_vd_cat_count.drop([\"\", \"Movies\", \"Shows\"])\n",
    "df_vd_cat_count[[\"dislike_count\", \"like_count\"]] = df_vd_cat_count[[\"dislike_count\", \"like_count\"]] / 1000000\n",
    "df_vd_cat_count[[\"dummmy\"]] = df_vd_cat_count[[\"dummmy\"]] / 1000000\n",
    "df_vd_cat_count[[\"view_count\"]] = df_vd_cat_count[[\"view_count\"]] / 1000000000\n",
    "df_vd_cat_count[[\"duration\"]] = df_vd_cat_count[[\"duration\"]] / 3.154e+7\n",
    "tmp = df_vd_cat_count.rename({\"dislike_count\": \"# Dislikes (M)\",\n",
    "    \"duration\": \"Duration (Years)\",\n",
    "    \"like_count\": \"# Likes (M)\",\n",
    "    \"view_count\": \"# Views (B)\",\n",
    "    \"dummmy\": \"# Videos (M)\"\n",
    "    }, axis=1)[[\"# Views (B)\", \"# Videos (M)\", \"# Likes (M)\", \"Duration (Years)\"]]\n",
    "tmp = tmp.append(tmp.sum(axis=0).rename(\"Total\"))\n",
    "print(round(tmp,1).to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra 1: Missing data on time-series data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(np.log10(df_sb_f[(df_sb_f.delta_subs == 0)].subs))\n",
    "np.mean((df_sb_f[(df_sb_f.delta_subs == 0)].subs > 9900) & (df_sb_f[(df_sb_f.delta_subs == 0)].subs > 10100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra 2: Completeness of # videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "fig, ax = plt.subplots(1, 1, figsize=(7, 3), sharex=False, gridspec_kw={\"wspace\": 0.30})\n",
    "x = abs(df_ch_f[\"videos_yt\"] - df_ch_f[\"videos_cc\"]) / pd.concat([df_ch_f[\"videos_yt\"], \n",
    "                                                                  df_ch_f[\"videos_cc\"]], axis=1).max(axis=1)\n",
    "\n",
    "\n",
    "x = sorted(x)\n",
    "p = 1. * np.arange(len(x))/(len(x) - 1)\n",
    "p95 = abs(p - 0.95).argmin()\n",
    "ax.plot(x, p, color=\"#e6ab02\")\n",
    "ax.scatter([x[p95]], [p[p95]], zorder=10, color=\"black\", marker=\"X\")\n",
    "ax.text(x[p95] + 0.025, p[p95] -0.0825, \n",
    "        \"For 95\\% of all \\n channels the relative  \\n difference is $\\leq$ 20\\%\", va=\"top\")\n",
    "ax.xaxis.grid(color=\"#CCCCCC\", ls=\":\")\n",
    "ax.yaxis.grid(color=\"#CCCCCC\", ls=\":\")\n",
    "ax.set_ylabel(\"Cumulative \\% of channels\")\n",
    "ax.set_xlabel(r'Relative difference between \\#videos' + '\\n(channelcrawler.com vs. YouTube)')\n",
    "ax.set_title(\"Completeness of videos per channel\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('ada')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d0662a494b2253db3bb976cfb5f0299b9f3e8f6fb30b7b3708db64640a69ca08"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
