{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d9b36cd",
   "metadata": {},
   "source": [
    "### Sponsors Regression analysis\n",
    "\n",
    "Regression analysis to try and understand more the effect of sponsors on the popularity of a video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d109495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/16 11:45:38 WARN Utils: Your hostname, LAPTOP-8QFB5E0N resolves to a loopback address: 127.0.1.1; using 172.28.70.21 instead (on interface eth0)\n",
      "22/12/16 11:45:38 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/16 11:45:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from pyspark.sql.functions import col, udf, explode\n",
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark as ps\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "import math\n",
    "from statsmodels.stats import diagnostic\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "config = ps.SparkConf().setAll([\n",
    "    ('spark.network.timeout', '3601s'),\n",
    "    ('spark.executor.heartbeatInterval', '3600s'),\n",
    "])\n",
    "sc = ps.SparkContext('local', '', conf=config)\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ec3ad1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_METADATA_SPONSORS_DOMAINS = 'data/yt_metadata_sponsor_en_domains.parquet'\n",
    "PATH_METADATAS_DOMAINS_SRC = 'data/yt_metadata_en_domains.parquet'\n",
    "PATH_ANALYSIS_DF = 'data/generated/sponsor_regression_df.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "100c7130",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sponsor_df = spark.read.parquet(PATH_METADATA_SPONSORS_DOMAINS)\n",
    "metadat_dt = metadatas_domains = spark.read.parquet(PATH_METADATAS_DOMAINS_SRC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "141af03b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- categories: string (nullable = true)\n",
      " |-- channel_id: string (nullable = true)\n",
      " |-- dislike_count: integer (nullable = true)\n",
      " |-- display_id: string (nullable = true)\n",
      " |-- duration: integer (nullable = true)\n",
      " |-- like_count: integer (nullable = true)\n",
      " |-- tags: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- upload_date: date (nullable = true)\n",
      " |-- view_count: long (nullable = true)\n",
      " |-- domains: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- domains_count: integer (nullable = true)\n",
      " |-- has_domains: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metadat_dt.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b688f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- display_id: string (nullable = true)\n",
      " |-- domains: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- domain_categories: string (nullable = true)\n",
      " |-- is_sponsored: boolean (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sponsor_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "643ebbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = sponsor_df.join(metadat_dt, on=[\"display_id\",\"domains\"], how=\"inner\")         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c762518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- display_id: string (nullable = true)\n",
      " |-- domains: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- domain_categories: string (nullable = true)\n",
      " |-- is_sponsored: boolean (nullable = true)\n",
      " |-- categories: string (nullable = true)\n",
      " |-- channel_id: string (nullable = true)\n",
      " |-- dislike_count: integer (nullable = true)\n",
      " |-- duration: integer (nullable = true)\n",
      " |-- like_count: integer (nullable = true)\n",
      " |-- tags: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- upload_date: date (nullable = true)\n",
      " |-- view_count: long (nullable = true)\n",
      " |-- domains_count: integer (nullable = true)\n",
      " |-- has_domains: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joined_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "369fc964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling the missing informations for likes/dislikes\n",
    "joined_df = joined_df.fillna(0,subset='dislike_count') \\\n",
    "                     .fillna(0,subset='like_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a38d6410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Th metric we will use to assess the \"popularity\" of a video\n",
    "joined_df = joined_df.withColumn('like_per_view', joined_df.like_count/ joined_df.view_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f66d77f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = joined_df.withColumn('dislike_per_view', joined_df.dislike_count / joined_df.view_count)\n",
    "joined_df = joined_df.fillna(0,subset='dislike_per_view')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16a4a9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_reg = joined_df.select(joined_df['is_sponsored'],joined_df['like_per_view'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d371fa19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to write the parquet file regression_urls with the columns you want to fit on :\n",
    "df_reg.write.parquet(PATH_ANALYSIS_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6866a1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "class DataSet(dict):\n",
    "    def __init__(self, path):\n",
    "        self.parquet = pq.ParquetDataset(path)\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        try:\n",
    "            return self.parquet.read([key]).to_pandas()[key]\n",
    "        except:\n",
    "            raise KeyError\n",
    "\n",
    "pd_df_reg = DataSet(PATH_ANALYSIS_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3a519ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_df_reg[\"is_sponsored\"] = pd_df_reg[\"is_sponsored\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bbc58797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:          like_per_view   R-squared:                       0.000\n",
      "Model:                            OLS   Adj. R-squared:                  0.000\n",
      "Method:                 Least Squares   F-statistic:                     8377.\n",
      "Date:                Fri, 16 Dec 2022   Prob (F-statistic):               0.00\n",
      "Time:                        12:06:53   Log-Likelihood:            -1.5027e+06\n",
      "No. Observations:            35516145   AIC:                         3.005e+06\n",
      "Df Residuals:                35516143   BIC:                         3.005e+06\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===========================================================================================\n",
      "                              coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------\n",
      "Intercept                   0.0212   4.76e-05    444.808      0.000       0.021       0.021\n",
      "C(is_sponsored)[T.True]     0.0096      0.000     91.528      0.000       0.009       0.010\n",
      "======================================================================================\n",
      "Omnibus:                384749766.735   Durbin-Watson:                           2.000\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):   1764558092339396476928.000\n",
      "Skew:                        5835.307   Prob(JB):                                 0.00\n",
      "Kurtosis:                34531123.118   Cond. No.                                 2.59\n",
      "======================================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "mod = smf.ols('like_per_view ~ C(is_sponsored)', data=pd_df_reg)\n",
    "np.random.seed(2)\n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21ced64",
   "metadata": {},
   "source": [
    "We observe that the p-values and confidence intervals are coherent (p-value < 0.05); If we take the entire dataset, we observe that in average we have : ${LikePerView = 0.0212 + IsSponsored*0.0096}$ \n",
    "\n",
    "\n",
    "We can thus see that on average the fact that a video is sponsored account for $\\frac{0.0096}{0.0212}*100 = 45$% of the likes per view on a video if we consider this simple model. \n",
    "\n",
    "\n",
    "Although we get a pretty positive analysis for the effect of sponsorship on videos we still need to keep in mind that we are only using a simple model and that lots of non-identified confounder could have some impact on the \"popularity\" metrics we use, just as a simple exemple we could take a look at the \"popularity\" of creator that tells their audience to \"like, comment and subscribe\" versus those that don't.\n",
    "\n",
    "Another key point that needs to be talked upon is akin to the question of the egg and the chicken, is the fact that sponsored videos tends to do better than un-sponsored one because the creator was already popular at the beginning or because sponsors have a significant effects, we will now try to see the effet at the individual channel level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e303eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since we will work at the channel level, we groupby each individual channel (defined by its id)\n",
    "gb_channel = joined_df.groupby('channel_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2e4e29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "117766"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/16 12:46:41 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 3659698 ms exceeds timeout 3601000 ms\n",
      "22/12/16 12:46:41 WARN SparkContext: Killing executors is not supported by current scheduler.\n"
     ]
    }
   ],
   "source": [
    "list_channel = []\n",
    "list_channel = joined_df.select('channel_id').distinct().collect()\n",
    "len(list_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba9ea65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we do the regression bqsed on the datas for each channel to get the coefficient we want\n",
    "list_coeff = []\n",
    "for channel in list_channel : \n",
    "    reg_channel = joined_df.where(df.channel_id == channel) \\\n",
    "                           .select(joined_df['is_sponsored'],joined_df['like_per_view'])\n",
    "    \n",
    "    pd_reg_channel = reg_channel.toPandas()\n",
    "    pd_reg_channel[\"is_sponsored\"] = pd_reg_channel[\"is_sponsored\"].astype(int)\n",
    "    \n",
    "    mod = smf.ols('like_per_view ~ C(is_sponsored)', data=pd_reg_channel)\n",
    "    np.random.seed(2)\n",
    "    res = mod.fit()\n",
    "    \n",
    "    list_coeff.append(res.params.values[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7176bdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot2')\n",
    "\n",
    "plt.hist(list_coeff)\n",
    "plt.xlabel(\"Value of the coefficient of 'is_sponsored'\")\n",
    "plt.ylabel(\"Counts\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfccc305",
   "metadata": {},
   "source": [
    "interprétation de l'hist => heavy tailed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
